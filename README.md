# ðŸ›¡ï¸ Text Shield: Privacy-Preserving Federated Learning for Text Classification

> **"Training smarter models, without ever touching your data."**  
> A federated learning simulation built from scratch to protect user privacy in NLP tasks.

---

## ðŸš€ Project Overview

**Text Shield** is a robust demonstration of **Federated Learning (FL)** applied to a multi-client text classification task. Designed with **privacy**, **scalability**, and **real-world deployment** in mind, this project simulates how edge devices collaboratively train a shared model **without centralizing their data**.

This isn't just a tech demo â€” it's a proof of concept for the **future of privacy-first machine learning**.

---

## ðŸ§  Problem Statement

Traditional machine learning requires aggregating all user data to a centralized server, introducing major **privacy risks** and **regulatory challenges** (like GDPR and HIPAA).

**Text Shield solves this problem by training on decentralized datasets.** Each client (or "user") retains local control of their data while participating in collaborative model improvement.

---

## ðŸ—ï¸ Architecture Overview

```plaintext
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Client 1   â”‚    â”‚  Client 2   â”‚    â”‚  Client 3   â”‚
 â”‚ Local Data  â”‚    â”‚ Local Data  â”‚    â”‚ Local Data  â”‚
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                  â”‚                  â”‚
      â–¼                  â–¼                  â–¼
  [Local Training]   [Local Training]   [Local Training]
      â”‚                  â”‚                  â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â–¼        â–¼         â–¼
     ðŸ” [Server Aggregation - FedAvg]
           â”‚
           â–¼
   ðŸ“¦ Updated Global Model
````

---

## ðŸ”„ Federated Learning Workflow

1. **Initialize Global Model** on the server.
2. For each round:

   * Clients receive the current global weights.
   * Each client trains on **local text data**.
   * Clients send **updated weights** (not data!) to the server.
   * The server aggregates weights via **Federated Averaging (FedAvg)**.
3. Evaluate the final model on a **central test set**.

---

## ðŸ“Š Results & Performance

### ðŸ§ª Final Evaluation Metrics

* **Test Accuracy:** 87.82%
* **Test Loss:** 0.3437
* **Rounds Trained:** 5
* **Clients Simulated:** 3

### ðŸ“ˆ Accuracy Per Round

```plaintext
Round 1 - Accuracy: ~70%
Round 2 - Accuracy: ~77%
Round 3 - Accuracy: ~82%
Round 4 - Accuracy: ~85%
Round 5 - Accuracy: ~87%
```

*(Visuals can be added with Matplotlib or TensorBoard)*

---


## ðŸŽ¥ Live Demo: Text Shield in Action

![Text Shield Federated Learning Demo](./output_demo_video/fl_demo_output.gif)

> ðŸ›¡ï¸ *Watch how local clients train independently and the server smartly aggregates the knowledge â€” all without touching private data.*  
> Welcome to the future of **privacy-first machine learning**.

---


## ðŸ§¾ Sample Predictions

```
Input: "This product is amazing and I love it!"
Prediction: Positive (âœ…)

Input: "I regret buying this. Waste of money."
Prediction: Negative (âŒ)
```

> âš ï¸ Note: Sample predictions based on synthetic dataset simulation for testing.

---

## ðŸ’¾ Model Export

The final trained model is saved as:

```python
model.save("global_model.h5")
```

âœ… Also convertible to **TensorFlow Lite** for mobile deployment.

---

## ðŸ“¦ Project Structure

```
FL_demo/
â”œâ”€â”€ client_data/           # Simulated datasets for each client
â”œâ”€â”€ fl_model.py            # Model architecture & compilation
â”œâ”€â”€ server.py              # FL orchestration logic
â”œâ”€â”€ utils.py               # Preprocessing & helper functions
â”œâ”€â”€ requirements.txt       # Python packages
â”œâ”€â”€ global_model.h5        # Saved final model
â””â”€â”€ README.md              # This file!
```

---

## ðŸ’¡ Key Learnings

* Hands-on understanding of **Federated Averaging**
* Importance of **privacy-aware training**
* Trade-offs in communication vs computation
* Simulating **non-IID client data** environments

---

## ðŸ”§ Requirements

```bash
Python 3.12
TensorFlow >= 2.10
NumPy
```

Install using:

```bash
pip install -r requirements.txt
```

---

## ðŸ‘©â€ðŸ’» Author

**Selcii** â€”
AI & Data Science Enthusiast | HealthTech Builder
*â€œBuilding the future, one neural net at a time.â€*

ðŸ”— [LinkedIn](https://linkedin.com/in/maria-selciya-m) â€¢  ðŸ§  (https://github.com/MICHAEL-MARIA16/federated_learning_demo)

---

## â­ Show Some Love

If you found this project valuable:

ðŸŒŸ Star it on GitHub
ðŸ´ Fork it
ðŸ“£ Share it with your ML crew

> Let's build a future where **privacy is the default**, not a privilege.

---
